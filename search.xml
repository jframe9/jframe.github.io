<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>随笔-随便 写点东西</title>
    <url>/2019/11/27/suibi/</url>
    <content><![CDATA[<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><blockquote>
<p><strong>语法糖</strong></p>
</blockquote>
<p>指计算机语言中添加的某种语法，这种语法对语言的功能并没有影响，但是<u>更方便程序员</u>使用。通常来说使用语法糖能够增加程序的可读性，从而减少程序代码出错的机会。</p>
<blockquote>
<p><strong>python for…else用法</strong></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">    print(i)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">'I am coming！'</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p><em>输出：</em></p>
<p>0</p>
<p>1</p>
<p>I am coming！</p>
</blockquote>
<p>结论：当for循环正常结束后，会执行else中的内容。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">'Sorry,你不爱我！'</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p><em>输出：</em></p>
</blockquote>
<p>没有输出，当for循环被打断时，else中的内容不再执行。</p>
<p> <strong>一旦…就….我觉得还是非常有效的。。。。</strong></p>
<p><a href="https://www.zhihu.com/question/35103080/answer/802025901" target="_blank" rel="noopener">https://www.zhihu.com/question/35103080/answer/802025901</a></p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>随心</tag>
      </tags>
  </entry>
  <entry>
    <title>report review</title>
    <url>/2019/11/26/report-review/</url>
    <content><![CDATA[<h3 id="怎么写Literature-review-文献综述"><a href="#怎么写Literature-review-文献综述" class="headerlink" title="怎么写Literature review(文献综述)?"></a>怎么写Literature review(文献综述)?</h3><blockquote>
<p>莫爲</p>
<p>知乎</p>
</blockquote>
<p>文献综述具体写作方法✍:</p>
<a id="more"></a>

<ul>
<li>首先根据你的论文topic想出<strong>5个</strong>关键词，依次输入谷歌学术搜索引擎（或者其他学校资源论文库） 。</li>
<li>在电脑里准备两个参考文献文件夹，一个名写Useful，另外一个文件夹写maybe useful。</li>
<li>接下来浏览搜索到的文献标题，看到和自己研究方向相关的题目就点进去，一目十行阅读文献，一共有三个部分尤其重要：Abstract(摘要)、Introduction(介绍)、Conclusion(结论)。文章的头尾部分</li>
<li>浏览后觉得和自己研究方向及论文主题相关度高的，保存到useful文件夹中，如果看完觉得emmmm…(作者老师原话，哈哈哈这种感觉只可意会不可言传)，大概就是觉得有那么点关系，但又不舍得pass的文献，就放进maybe useful文件夹 。</li>
<li>两个文件夹各存满12篇阅读文献，首先从Uesful文件夹开始。一篇一篇<strong>精读</strong>这些文献。精读的时就按照自己平时的方法，多做笔记，摘录提取<strong>key point</strong>。</li>
<li>精读的过程不是一遍两遍就能完成的，每次读一遍，你就会有不同的体会。接下来，你可以慢慢关注下<strong>methodology,</strong>在阅读的过程中开始思考自己文章的论证方法，为你的research method部分做准备，如果是实证论文，也可以开始想一下自己模型的雏形。</li>
<li>读第二遍第三遍的时候，在电脑打开word，开始<strong>一边读一边记录</strong>要写进文献综述的部分，注意要用<strong>自己的话重述</strong>，写的时候加上标注。</li>
<li>最后将所有文献进行整理引用，把同一小主题的贴在同一段中，也可以加上小标题，使自己的文章更有逻辑，条理更清晰 。</li>
<li>尽量找出不同论文中矛盾冲突的点，凸显出学术圈思维碰撞的火花～比如某些大佬实证得出两个变量是正相关，而其他几位大佬发现负相关，尽量找出不同论文中矛盾冲突的点，凸显出学术圈思维碰撞的火花～比如某些大佬实证得出两个变量是正相关，而其他几位大佬发现负相关。</li>
<li>学会索引去看文献引用的文献（我戏称为文献爸爸 ）和文献被引用的文献（文献儿子 ），去看理论是如何发展的，也会在此过程中发现更多好文献，不断扩充自己的reference文献库！</li>
</ul>
]]></content>
      <categories>
        <category>经验分享</category>
      </categories>
      <tags>
        <tag>reviews</tag>
        <tag>experience</tag>
      </tags>
  </entry>
  <entry>
    <title>German to English</title>
    <url>/2019/11/24/German-to-English/</url>
    <content><![CDATA[<h3 id="德语译英语"><a href="#德语译英语" class="headerlink" title="德语译英语"></a>德语译英语</h3><p>在这份教程中，我们将会在数据集上训练一个德语-&gt;英语的<code>Sockeye</code>机器翻译模型。（数据集是2017年<code>WNT</code>）</p>
<a id="more"></a>

<h4 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h4><p><code>Sockeye</code>期望标记数据作为输入。在本教程中，我们使用已经标记的数据。但是，请记住这一点，以便与<code>Sockeye</code>一起使用任何其他数据集。除了标记化之外，我们还将使用字节对编码(BPE)将单词拆分为子单词。为了做到这一点，我们使用了一个叫做<a href="https://github.com/rsennrich/subword-nmt" target="_blank" rel="noopener">subword-nmt</a>. 运行以下命令来设置该工具:</p>
<blockquote>
<p>git clone <a href="https://github.com/rsennrich/subword-nmt.git" target="_blank" rel="noopener">https://github.com/rsennrich/subword-nmt.git</a></p>
<p>export PYTHONPATH=$(pwd)/subword-nmt:$PYTHONPATH</p>
</blockquote>
<p>为了可视化对齐，我们需要<code>matplotlib</code>。如果你没有这个库，可以通过以下指令来安装:</p>
<blockquote>
<p>pip install matplotlib</p>
</blockquote>
<p>我们将使用<code>Tensorboard</code>及其<code>MXNet适配器mxboard</code>来可视化培训进度。安装使用:</p>
<blockquote>
<p>pip install tensorboard mxboard</p>
</blockquote>
<h4 id="GPU"><a href="#GPU" class="headerlink" title="GPU"></a>GPU</h4><p>所有的命令都是假设你在CPU的运行环境下，如果你想使用GPU，你可以通过移除<code>--use-cpu</code>来实现，对于多个gpu，您可以通过<code>--device-ids</code>命令行参数使用它们。</p>
<h4 id="Data（数据）"><a href="#Data（数据）" class="headerlink" title="Data（数据）"></a>Data（数据）</h4><p>我们将使用WMT 2017新闻翻译共享任务提供的数据。使用以下命令下载数据:</p>
<blockquote>
<p>wget <a href="http://data.statmt.org/wmt17/translation-task/preprocessed/de-en/corpus.tc.de.gz" target="_blank" rel="noopener">http://data.statmt.org/wmt17/translation-task/preprocessed/de-en/corpus.tc.de.gz</a><br>wget <a href="http://data.statmt.org/wmt17/translation-task/preprocessed/de-en/corpus.tc.en.gz" target="_blank" rel="noopener">http://data.statmt.org/wmt17/translation-task/preprocessed/de-en/corpus.tc.en.gz</a><br>gunzip corpus.tc.de.gz<br>gunzip corpus.tc.en.gz<br>curl <a href="http://data.statmt.org/wmt17/translation-task/preprocessed/de-en/dev.tgz" target="_blank" rel="noopener">http://data.statmt.org/wmt17/translation-task/preprocessed/de-en/dev.tgz</a> | tar xvzf -</p>
</blockquote>
<h4 id="Preprocessing-预处理数据"><a href="#Preprocessing-预处理数据" class="headerlink" title="Preprocessing(预处理数据)"></a>Preprocessing(预处理数据)</h4><p>数据已经被标记了。此外，我们将把单词分成子单词。首先，我们需要建立我们的BPE词汇表:</p>
<blockquote>
<p>python -m learn_joint_bpe_and_vocab –input corpus.tc.de corpus.tc.en <br>                                    -s 30000 <br>                                    -o bpe.codes <br>                                    –write-vocabulary bpe.vocab.de bpe.vocab.en</p>
</blockquote>
<p>这将创建一个联合的源和目标BPE词汇表。接下来，我们使用应用字节对编码到我们的培训和开发数据:</p>
<blockquote>
<p>python -m apply_bpe -c bpe.codes –vocabulary bpe.vocab.de –vocabulary-threshold 50 &lt; corpus.tc.de &gt; corpus.tc.BPE.de<br>python -m apply_bpe -c bpe.codes –vocabulary bpe.vocab.en –vocabulary-threshold 50 &lt; corpus.tc.en &gt; corpus.tc.BPE.en</p>
<p>python -m apply_bpe -c bpe.codes –vocabulary bpe.vocab.de –vocabulary-threshold 50 &lt; newstest2016.tc.de &gt; newstest2016.tc.BPE.de<br>python -m apply_bpe -c bpe.codes –vocabulary bpe.vocab.en –vocabulary-threshold 50 &lt; newstest2016.tc.en &gt; newstest2016.tc.BPE.en</p>
</blockquote>
<p>查看数据，你可以看到单词是如何被特殊的序列<code>@@</code>分隔成子单词的:</p>
<blockquote>
<p>Globaldarlehen sind Kreditlinien an zwischengeschaltete Institute -&gt; Glob@@ al@@ dar@@ lehen sind Kredit@@ linien an zwischen@@ gesch@@ al@@ tete Institute</p>
</blockquote>
<h4 id="Training（训练）"><a href="#Training（训练）" class="headerlink" title="Training（训练）"></a>Training（训练）</h4><p>数据预处理后，我们就可以开始训练。请注意，<code>Sockeye</code>将把所有训练数据加载到内存中，以便能够在每个<code>epoch</code>之后轻松地重新洗牌。根据可用内存的大小，您可能希望减少本教程的培训语料库的大小:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># (Optional: run this if you have limited RAM on the training machine)如果训练空间有限，就使用这个指令运行</span></span><br><span class="line">head -n <span class="number">200000</span> corpus.tc.BPE.de &gt; corpus.tc.BPE.de.tmp &amp;&amp; mv corpus.tc.BPE.de.tmp corpus.tc.BPE.de</span><br><span class="line">head -n <span class="number">200000</span> corpus.tc.BPE.en &gt; corpus.tc.BPE.en.tmp &amp;&amp; mv corpus.tc.BPE.en.tmp corpus.tc.BPE.en</span><br></pre></td></tr></table></figure>

<p>在我们开始训练之前，我们会准备训练数据，将其分解成碎片，并以矩阵格式序列化:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python -m sockeye.prepare_data \</span><br><span class="line">                        -s corpus.tc.BPE.de \</span><br><span class="line">                        -t corpus.tc.BPE.en \</span><br><span class="line">                        -o train_data</span><br></pre></td></tr></table></figure>

<p>虽然这是一个可选步骤，但它的优点是大大降低了训练开始前所需的时间，并且限制了内存使用，因为一次只将一个碎片加载到内存中。</p>
<p>我们现在可以开始训练过程了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python -m sockeye.train -d train_data \</span><br><span class="line">                        -vs newstest2016.tc.BPE.de \</span><br><span class="line">                        -vt newstest2016.tc.BPE.en \</span><br><span class="line">                        --encoder rnn \</span><br><span class="line">                        --decoder rnn \</span><br><span class="line">                        --num-embed <span class="number">256</span> \</span><br><span class="line">                        --rnn-num-hidden <span class="number">512</span> \</span><br><span class="line">                        --rnn-attention-type dot \</span><br><span class="line">                        --max-seq-len <span class="number">60</span> \</span><br><span class="line">                        --decode-<span class="keyword">and</span>-evaluate <span class="number">500</span> \</span><br><span class="line">                        --use-cpu \</span><br><span class="line">                        -o wmt_model</span><br></pre></td></tr></table></figure>

<p>训练使用的是1层的双向LSTM模型来编码，带有一层的点在注意力机制来解码。<code>Sockeye</code>提供了关于模型架构的不同选项，例如：残差网络堆叠RNN（<code>--num-layers</code>, <code>--rnn-residual-connections</code>），<a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">ransformer</a>编码和解码（<code>--encoder transformer</code>, <code>--decoder transformer</code>），<a href="https://arxiv.org/pdf/1705.03122" target="_blank" rel="noopener">ConvS2S</a>(<code>--encoder cnn</code>, <code>--decoder cnn</code>),各种RNN（<code>--rnn-cell-type</code>）以及注意力机制的类型（<code>--attention-type</code>）等等。</p>
<p>模型中还包含有几个参数用来控制训练过程本身，除非你指定一个不同的优化器（<code>--optimizer</code>）,否则将使用Adam。此外，你可以控制批次大小（<code>--batch-size</code>）,lr schedule(–learning-rate-schedule),和其他与训练相关的参数。</p>
<p>训练将持续进行，直到验证的复杂性停止改善。<code>Sockeye</code>在与训练相同的设备上运行的每个检查点上，在单独的进程中启动一个解码器，以评估诸如<code>BLEU</code>之类的指标。需要注意的是，在块上，分数被计算出来，然后提供给<code>Sockeye</code>，例如：在本教程中，<code>BLEU</code>将根据我们在上面创建的子单词进行计算。作为验证的另一种基于复杂度的早期停止，你可以根据<code>BLEU</code>评分提前停止（<code>--optimized-metric bleu</code>）。</p>
<p>为了确保解码器在下一个检查点之前完成，可以对<code>BLEU</code>分数计算的验证集进行子采样。例如： <code>--decode-and-evaluate 500</code> 将会解码并且评估<code>BLEU</code>在一个随机500的子序列上。我们对随机子集抽样一次，并在训练期间和跨训练期间通过固定随机种子保持它不变。因此，验证<code>BLEU</code>在训练中的得分是可比较的。复杂度(Perplexity)不受此影响，仍然在完整的验证集上计算。</p>
<p>在这个数据集上训练数据需要一段时间。下一部分我们将会讲解你如何能够监控训练进程。</p>
<h5 id="Monitoring-training-progress"><a href="#Monitoring-training-progress" class="headerlink" title="Monitoring training progress"></a>Monitoring training progress</h5><p>下边有三种方式用来跟踪训练进程：通过训练日志和日志文件、一些标准文件、还有<code>Tensorboard</code>。除了在标准输出（<code>stdout</code>）上打印培训和验证指标之外，<code>Sockeye</code>也通过文件<code>wmt_model/metrics</code>来跟踪他们。在哪里你可以找到所有在<code>checkpointing</code>期间计算的相关的指标。</p>
<p><code>Tensorboard</code>通过浏览器监控训练指标和验证指标。如果你安装了<code>mxboard</code>,<code>Scokeye</code>将会将训练进行以日志格式存放在<code>Tensorboard</code>文件夹中，这个文件夹可以再<code>Tensorboard</code>中可视化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tensorboard --logdir .</span><br></pre></td></tr></table></figure>

<p>Once tensorboard is up and running you can check out the learning curves by opening <a href="http://localhost:6006" target="_blank" rel="noopener">http://localhost:6006</a>.</p>
<p><img src="/images/photo/tensorboard.png" alt="tensorboard"></p>
<p>现在，甚至在培训结束之前，如果至少有一个检查点被写到磁盘上，您就已经可以开始使用模型进行转换了。</p>
<h4 id="Translation"><a href="#Translation" class="headerlink" title="Translation"></a>Translation</h4><p>当使用<code>Sockeye</code>进行翻译时，重要的是要记住它期望的输入类型与训练期间看到的输入类型相同。在这份教程中，我们输入的是子词单元，这些单元通过字节对编码获得。因此，因此，我们需要在将一个句子输入到<code>Sockeye</code>之前，应用相同类型的预处理。所有在训练中没有看到的符号将被替换为<unk>符号。当在训练过程中观察到<unk>符号时，模型也会在输出中产生这个符号。注意，由于我们使用上面的<code>BPE</code>进行预处理的方式，模型实际上不会观察到任何<unk>符号。在下面的示例中，我们将使用来自开发集的一个语句，该语句已经被标记，字节对对其进行编码。翻译之后，我们合并连续的字节对，产生一个标记化的翻译句子。这可以通过以下命令完成:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">echo <span class="string">"er ist so ein toller Kerl und ein Familienvater ."</span> | \</span><br><span class="line">  python -m apply_bpe -c bpe.codes --vocabulary bpe.vocab.en \</span><br><span class="line">                                   --vocabulary-threshold <span class="number">50</span> | \</span><br><span class="line">  python -m sockeye.translate -m wmt_model <span class="number">2</span>&gt;/dev/null | \</span><br><span class="line">  sed -r <span class="string">'s/@@( |$)//g'</span></span><br><span class="line"></span><br><span class="line">he <span class="keyword">is</span> a great guy <span class="keyword">and</span> a family father .</span><br></pre></td></tr></table></figure>

<p>在解码期间，<code>Sockeye</code>将会运行一个波束搜索。你可以设置波束的大小（<code>--beam-size</code>）或者改变其他编码参数，例如：<code>--softmax-temperature</code>和<code>--length-penalty-alpha</code></p>
<h5 id="Alignment-visualization"><a href="#Alignment-visualization" class="headerlink" title="Alignment visualization"></a>Alignment visualization</h5><p><code>Sockeye</code>不仅提供文本输出，也可以有其他类型的输出。下述命令将会实例对齐矩阵。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">echo <span class="string">"er ist so ein toller Kerl und ein Familienvater ."</span> | \</span><br><span class="line">  python -m apply_bpe -c bpe.codes --vocabulary bpe.vocab.en \</span><br><span class="line">                                   --vocabulary-threshold <span class="number">50</span> | \</span><br><span class="line">  python -m sockeye.translate -m wmt_model --output-type align_plot</span><br></pre></td></tr></table></figure>

<p>这将创建一个文件align_1.png，看起来像这样:</p>
<p><img src="/images/photo/align.png" alt="align"></p>
<p>注意，对齐图显示的是子单词单位，而不是标记，因为这是<code>Sockeye</code>在翻译期间使用的表示。此外，您可以看到特殊的句尾符号</s>被添加到目标句中。</p>
<h5 id="Embedding-inspection"><a href="#Embedding-inspection" class="headerlink" title="Embedding inspection"></a>Embedding inspection</h5><p>您可以检查模型在培训期间学到的嵌入。<code>Sockeye</code>包含一个工具，用于计算嵌入空间中所有类型的成对相似性(欧几里德距离)。给定一个查询标记，它将返回空间中最近的邻居。你可以这样运行它:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">echo <span class="string">"haus"</span> | python3 -m sockeye.embeddings -m wmt_model -s source</span><br><span class="line">[INFO:__main__] Arguments: Namespace(checkpoint=<span class="literal">None</span>, gamma=<span class="number">1.0</span>, k=<span class="number">5</span>, model=<span class="string">'wmt_model'</span>, norm=<span class="literal">False</span>, side=<span class="string">'source'</span>)</span><br><span class="line">Input: haus</span><br><span class="line">haus id=<span class="number">35</span></span><br><span class="line">  gebaeude id=<span class="number">68</span> sim=<span class="number">0.8498</span></span><br><span class="line">  Haus id=<span class="number">1759</span> sim=<span class="number">0.1441</span></span><br><span class="line">  hauser id=<span class="number">295</span> sim=<span class="number">0.0049</span></span><br></pre></td></tr></table></figure>

<p>(你自己的输出可能看起来不一样)</p>
<h5 id="Model-ensembling"><a href="#Model-ensembling" class="headerlink" title="Model ensembling"></a>Model ensembling</h5><p>深度学习模型通常从模型集成中获益。在模型集成中，我们用不同的种子训练多个模型（<code>Sockeye</code>有一个参数<code>--seed</code>）。然后我们就可以把这些模型提供给<code>Sockeye</code> translation <code>CLI</code>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">echo <span class="string">"er ist so ein toller Kerl und ein Familienvater ."</span> | \</span><br><span class="line">  python -m apply_bpe -c bpe.codes --vocabulary bpe.vocab.en \</span><br><span class="line">                                   --vocabulary-threshold <span class="number">50</span> | \</span><br><span class="line">  python -m sockeye.translate -m wmt_model wmt_model_seed2 wmt_model_seed3 <span class="number">2</span>&gt;/dev/null | \</span><br><span class="line">  sed -r <span class="string">'s/@@( |$)//g'</span></span><br><span class="line"></span><br><span class="line">he <span class="keyword">is</span> a great guy <span class="keyword">and</span> a family father .</span><br></pre></td></tr></table></figure>

<p>由于我们还没有训练多个模型，我们可以简单地在同一个模型中输入多次:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">echo <span class="string">"er ist so ein toller Kerl und ein Familienvater ."</span> | \</span><br><span class="line">  python -m apply_bpe -c bpe.codes --vocabulary bpe.vocab.en \</span><br><span class="line">                                   --vocabulary-threshold <span class="number">50</span> | \</span><br><span class="line">  python -m sockeye.translate -m wmt_model wmt_model wmt_model <span class="number">2</span>&gt;/dev/null | \</span><br><span class="line">  sed -r <span class="string">'s/@@( |$)//g'</span></span><br><span class="line"></span><br><span class="line">he <span class="keyword">is</span> a great guy <span class="keyword">and</span> a family father .</span><br></pre></td></tr></table></figure>

<p>在内部，<code>Sockeye</code>将运行每个模型并结合预测。如果所有的模型都是相同的，你当然会得到相同的预测，代价是多次运行相同的模型。<strong>然而，重点主要是展示如何运行集成模型。</strong></p>
<h4 id="Checkpoint-averaging"><a href="#Checkpoint-averaging" class="headerlink" title="Checkpoint averaging"></a>Checkpoint averaging</h4><p>不需要训练多个模型的模型集成的另一种方法是从不同的检查点平均参数。虽然集成基本上是免费的，但这通常会导致较小的收益。当然，您也可以创建一个检查点平均模型的集合。<code>Sockeye</code>提供了一个<code>CLI</code>，它组合了训练模型的参数文件。在下面，我们创建一个模型目录的副本，然后用一个平均参数检查点文件替换到最佳参数的链接:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cp -r wmt_model wmt_model_avg</span><br><span class="line">python -m sockeye.average -o wmt_model_avg/param.best wmt_model</span><br></pre></td></tr></table></figure>

<h4 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h4><p>Congratulations! You have successfully trained your first real Sockeye translation model. On top of that you know how to track training progress, how to translate, how to combine models through checkpointing or ensembling and more.</p>
]]></content>
      <categories>
        <category>机器翻译</category>
      </categories>
      <tags>
        <tag>tutorials</tag>
        <tag>example</tag>
      </tags>
  </entry>
  <entry>
    <title>Sequence copy task</title>
    <url>/2019/11/22/tutorials/</url>
    <content><![CDATA[<h3 id="Sequence-copy-task"><a href="#Sequence-copy-task" class="headerlink" title="Sequence copy task"></a>Sequence copy task</h3><p>这篇教程将会向你展示<code>Sockeye</code>在一些简单任务上简单应用：复制一个序列。我们将生成由可变长度的数字组成的序列。然后，任务是训练一个模型，该模型将序列从源复制到目标。这个任务一方面非常困难，足够有趣，另一方面可以快速地训练一个模型。</p>
<a id="more"></a>

<h4 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h4><p>对于这份教程，我们假定你已经成功安装<code>Sockeye</code>。我们将会使用<code>Sockeye</code>仓库中的脚本，因此你可以克隆仓库或者手动下载脚本。需要提醒的是：所有的环境都在<strong>Python 3</strong>上执行，因此，根据您的设置，您可能不得不使用下面的<strong>python 3</strong>来<strong>替换</strong>python。下面的所有命令都假设您在CPU上运行。如果你有一个可用的<code>GPU</code>，你可以简单地移除使用指令<code>--use-cpu</code>。</p>
<h4 id="生成数据"><a href="#生成数据" class="headerlink" title="生成数据"></a>生成数据</h4><p>作为第一步，我们将生成一个由随机数字序列组成的合成数据集。然后将这些序列分割为不相交的训练集和开发集。运行以下命令创建数据集:</p>
<blockquote>
<p>wget <a href="https://raw.githubusercontent.com/awslabs/sockeye/master/docs/tutorials/seqcopy/genseqcopy.py" target="_blank" rel="noopener">https://raw.githubusercontent.com/awslabs/sockeye/master/docs/tutorials/seqcopy/genseqcopy.py</a></p>
<p>python genseqcopy.py     # 生成数据</p>
</blockquote>
<p>当运行脚本后，你会返现在<code>data/</code>文件夹下有一个训练集（<code>train.source</code>, <code>train.target</code>）和一个开发集（<code>dev.source</code>, <code>dev.target</code>）。产生的序列类似于下面数据：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2 3 5 5 4 6 7 0 3 8 10 9 3 6</span><br><span class="line">9 9 1 5 3 0 5 4 0 8 8 5 7 7 8 7 3 1 0</span><br><span class="line">9 1 9 7 9 1 9 9 9 3 9 3 2 8 0 1 6 10 4 3 1 9 2 7 1 5 7 7 5 5</span><br><span class="line">2 1 4 10 7 7 7 2 10 9 4 9 9 7 8 4 10 6 8 2 6 7 5 3 2</span><br><span class="line">4 6 0 7 8 8 6 3 4 10 2 10 6 9 5 3</span><br><span class="line">8 0 5 4 1 8 0 8 7 4 4 0 0 9 5 8 9</span><br></pre></td></tr></table></figure>

<h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><p>现在我们有了一些训练数据，我们可以训练我们的模型。通过以下命令开始我们的训练：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python3 -m sockeye.train -s data/train.source \</span><br><span class="line">                         -t data/train.target \</span><br><span class="line">                         -vs data/dev.source \</span><br><span class="line">                         -vt data/dev.target \</span><br><span class="line">                         --encoder rnn --decoder rnn \</span><br><span class="line">                         --num-layers <span class="number">1</span>:<span class="number">1</span> \</span><br><span class="line">                         --num-embed <span class="number">32</span> \</span><br><span class="line">                         --rnn-num-hidden <span class="number">64</span> \</span><br><span class="line">                         --rnn-attention-type dot \</span><br><span class="line">                         --use-cpu \</span><br><span class="line">                         --metrics perplexity accuracy \</span><br><span class="line">                         --max-num-checkpoint-<span class="keyword">not</span>-improved <span class="number">3</span> \</span><br><span class="line">                         -o seqcopy_model</span><br></pre></td></tr></table></figure>

<p>这将训练一个1层的<code>RNN</code>模型，<code>双向LSTM</code>作为编码器，<code>单向LSTM</code>作为解码器。<code>RNN</code>有64个隐藏层单元，我们学习的嵌入大小32。查看日志，我们可以看到我们的训练数据是根据桶的长度分配的。此外，<code>Sockeye</code>将负责正确填充序列和屏蔽网络的相关部分，以处理可变长度的序列。</p>
<h5 id="指标和检查点"><a href="#指标和检查点" class="headerlink" title="指标和检查点"></a>指标和检查点</h5><p>在训练期间，<code>Sockeye</code>将打印训练和验证数据的相关指标。指标可以通过使用<code>--metrics</code>参数。每次创建检查点时都要评估验证指标。在检查点期间，当前的模型参数被保存到模型目录中，并对当前的验证分数进行评估。默认情况下，<code>Sockeye</code>将每1000次更新创建一个检查点。这可以通过<code>--checkpoint-interval</code>参数进行调整。</p>
<p>从日志中可以看出，最初的精度在0.1左右:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">[INFO:sockeye.training] Training started.</span><br><span class="line">[INFO:sockeye.callback] Early stopping by optimizing &apos;perplexity&apos;</span><br><span class="line">[INFO:root] Epoch[0] Batch [50]  Speed: 683.23 samples/sec perplexity=14.104128 accuracy=0.092011</span><br><span class="line">[INFO:root] Epoch[0] Batch [100] Speed: 849.97 samples/sec perplexity=13.036482 accuracy=0.096760</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>对于大小为10的词汇表，这基本上意味着模型是随机猜测的。随着训练的进展，我们看到在14个epochs之后，<code>accuracy</code>上升到~1.0，<code>perplexity</code>下降到 ~ 1.0。<code>Sockeye</code>根据检查点跟踪的验证指标执行早期停止。一旦几个检查点的验证指标没有改善，训练就会停止。可以调整容忍的没有改进的检查点的数量(<code>--max-num-checkpoint-not-improved</code>)。</p>
<h5 id="训练好的模型"><a href="#训练好的模型" class="headerlink" title="训练好的模型"></a>训练好的模型</h5><p>可以在<code>seqcopy_model</code>文件夹中找到经过训练的模型。该文件夹包含训练后运行模型所需的所有内容。许多重要的<code>params.best</code>包含具有最佳验证分数的参数。在训练中，<code>params.best</code>将不断更新，以指向当前的最佳参数。这意味着即使模型仍在训练中，您也可以使用model文件夹进行翻译，如下一节所述。所有其他参数都可以在名为<code>param.$NUM_CHECKPOINT</code>的文件中找到。<code>config</code>中包含所有的模型参数以及对训练期间使用的数据集的引用。<code>version</code> 参考用于训练的<code>Sockeye</code>版本，以检查与用于解码的版本的潜在兼容性问题。</p>
<p>另外，我们保留了您在<code>标准输出</code>上看到的打印日志的副本。源词汇表和目标词汇表存储在<code>vocab.src.json</code>和 <code>vocab.trg.json</code>中。如果你打开这个文件，你可以看到除了数字之外，<code>Sockeye</code>还添加了一些特殊的符号来表示句子的边界、未知的单词和填充符号。</p>
<h4 id="Translation"><a href="#Translation" class="headerlink" title="Translation"></a>Translation</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt; echo <span class="string">"7 6 7 7 10 2 0 8 0 5 7 3 5 6 4 0 0 2 10 0"</span> | \</span><br><span class="line">  python -m sockeye.translate -m seqcopy_model --use-cpu</span><br><span class="line"></span><br><span class="line">        <span class="number">7</span> <span class="number">6</span> <span class="number">7</span> <span class="number">7</span> <span class="number">10</span> <span class="number">2</span> <span class="number">0</span> <span class="number">8</span> <span class="number">0</span> <span class="number">5</span> <span class="number">7</span> <span class="number">3</span> <span class="number">5</span> <span class="number">6</span> <span class="number">4</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">10</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>注意，该模型是在10到30个字符之间的序列上训练的。因此，对于长度小于10个字符的序列，模型很可能会遇到一些困难。默认情况下，<code>Sockeye</code>将阅读标注输入中的句子并在标准输出上打印翻译。</p>
<p>在内部，<code>Sockeye</code>将运行一个波束搜索，以便(近似地)找到概率最高的译文。</p>
<p>除了使用具有最佳验证分数的参数外，我们还可以使用其他使用<code>-c</code>参数的检查点，在模型收敛之前的训练中使用检查点:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt; echo <span class="string">"7 6 7 7 10 2 0 8 0 5 7 3 5 6 4 0 0 2 10 0"</span> | \</span><br><span class="line">  python -m sockeye.translate -m seqcopy_model --use-cpu -c <span class="number">3</span></span><br><span class="line"></span><br><span class="line">        <span class="number">7</span> <span class="number">6</span> <span class="number">7</span> <span class="number">7</span> <span class="number">10</span> <span class="number">2</span> <span class="number">0</span> <span class="number">8</span> <span class="number">0</span> <span class="number">5</span> <span class="number">7</span> <span class="number">0</span> <span class="number">7</span> <span class="number">3</span> <span class="number">5</span> <span class="number">6</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">10</span></span><br></pre></td></tr></table></figure>

<p>由于模型还没有收敛，所以在复制序列时仍然会犯一些错误。</p>
]]></content>
      <categories>
        <category>机器翻译</category>
      </categories>
      <tags>
        <tag>tutorials</tag>
        <tag>example</tag>
      </tags>
  </entry>
  <entry>
    <title>亚马逊机器翻译框架-训练说明文档(2)</title>
    <url>/2019/11/20/%E4%BA%9A%E9%A9%AC%E9%80%8A%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E6%A1%86%E6%9E%B6-%E8%AE%AD%E7%BB%83%E8%AF%B4%E6%98%8E%E6%96%87%E6%A1%A3-2/</url>
    <content><![CDATA[<h3 id="Translation"><a href="#Translation" class="headerlink" title="Translation"></a>Translation</h3><p>解码过程的实现，主要是通过<code>sockeye.translate</code>模块。</p>
<a id="more"></a>

<blockquote>
<p>python -m sockeye.translate</p>
</blockquote>
<p>这一步仅仅需要一个<code>--models</code>参数，它指向的是训练模型<code>&lt;model_dir&gt;</code>文件夹路径。<code>sockeye</code>默认从最好的<code>checkpoints</code>参数，并且使用他们来做翻译。你可以指定特定的参数从特定的<code>checkpoint</code>中，使用的指令是<code>--checkpoints X</code>。</p>
<p>你可以使用<code>--beam-size</code>控制beam尺寸的大小，通过<code>--max-input-length</code>控制输入的最大长度。一旦序列长度超过最大长度，就会被忽略。</p>
<p>从标准输入读取输入，然后将输出写入标准输出。一旦使用了输入，<code>CLI</code>将记录转换速度。和训练过程一样，第一块GPU是默认使用的。需要注意的是多GPU目前还不支持。需要使用CPU，请用<code>--use-cpu</code>。</p>
<p>使用<code>--help</code>选线，查看完整列表选项。</p>
<h5 id="整体解码"><a href="#整体解码" class="headerlink" title="整体解码"></a>整体解码</h5><p>Sockeye通过指定多个模型目录和多个检查点来支持集成解码。列表必须有相同的长度，这样，第一个给定的检查点将从第一个模型目录中获取，从第二个目录中指定的第二个检查点，等等。</p>
<blockquote>
<p> python -m sockeye.translate –models [<m1prefix> <m2prefix>] –checkpoints [<cp1> <cp2>]</p>
</blockquote>
<h5 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h5><p>转换CLI的默认模式是将转换输出到STDOUT。</p>
]]></content>
      <categories>
        <category>机器翻译</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>machine translate</tag>
      </tags>
  </entry>
  <entry>
    <title>亚马逊机器翻译框架-训练说明文档(1)</title>
    <url>/2019/11/19/%E4%BA%9A%E9%A9%AC%E9%80%8A%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E6%A1%86%E6%9E%B6-%E8%AE%AD%E7%BB%83%E8%AF%B4%E6%98%8E%E6%96%87%E6%A1%A3/</url>
    <content><![CDATA[<blockquote>
<p>英文版本地址：<a href="https://awslabs.github.io/sockeye/training.html" target="_blank" rel="noopener">https://awslabs.github.io/sockeye/training.html</a></p>
</blockquote>
<h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><center>

<p>   <img src="/images/photo/dockeye.png" alt="dockeye"></p>
</center>

<a id="more"></a>

<h4 id="数据表示"><a href="#数据表示" class="headerlink" title="数据表示"></a>数据表示</h4><p><code>Sockeye</code>在训练时间可以凭借<code>--source</code> 以及<code>--target</code>命令行，按行来读取平行语料中的数据。您还可以提前准备数据并将其作为<code>MXNet NDArrays</code>格式转储到磁盘。这基本上消除了运行训练时的数据加载时间(因为需要三次传递原始数据)，也能减少内存消耗，<strong>因为准备好的数据也被放入随机的碎片中</strong>（默认情况下每行有100万行）。运行数据表示，你可以按照下面的命令：</p>
<p>对应文件是：<strong>prepare_data.py</strong></p>
<blockquote>
<p>python -m sockeye.prepare_data</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;usage:  prepare_data.py  [-h] --source SOURCE</span><br><span class="line">                 [--source-factors SOURCE_FACTORS [SOURCE_FACTORS ...]]</span><br><span class="line">                 --target TARGET [--source-vocab SOURCE_VOCAB]</span><br><span class="line">                    [--target-vocab TARGET_VOCAB]</span><br><span class="line">                    [--source-factor-vocabs SOURCE_FACTOR_VOCABS [SOURCE_FACTOR_VOCABS ...]]</span><br><span class="line">                    [--shared-vocab] [--num-words NUM_WORDS]</span><br><span class="line">                    [--word-min-count WORD_MIN_COUNT]</span><br><span class="line">                    [--pad-vocab-to-multiple-of PAD_VOCAB_TO_MULTIPLE_OF]</span><br><span class="line">                    [--no-bucketing] [--bucket-width BUCKET_WIDTH]</span><br><span class="line">                    [--max-seq-len MAX_SEQ_LEN]</span><br><span class="line">                    [--num-samples-per-shard NUM_SAMPLES_PER_SHARD]</span><br><span class="line">                    [--min-num-shards MIN_NUM_SHARDS] [--seed SEED]</span><br><span class="line">                    --output OUTPUT</span><br><span class="line">   prepare_data.py: error: the following arguments are required: --source/-s, --target/-t, --output/-o</span><br></pre></td></tr></table></figure>
</blockquote>
<p>最重要的参数是上面所需要的（<code>--source</code>, <code>--target</code>, <code>--output</code>将确定预处理文件的写入路径。）</p>
<ul>
<li>其他比较重要的参数：<ul>
<li><code>--shared-vocab</code>: 在语料库的源方和目标方之间产生一个共享的词汇表。</li>
<li><code>--num-samples-per-shard</code>: 控制共享尺寸。</li>
</ul>
</li>
</ul>
<p>在训练时间（下一节），用指定的预训练数据来代替源数据和目标数据。</p>
<h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><p>训练是通过<code>sockeye.train</code>这个模块。基础的用法，下面将会给出：</p>
<p>对应文件：<strong>train.py</strong></p>
<blockquote>
<p>python -m sockeye.train</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">usage: train.py [-h]</span><br><span class="line">		--source SOURCE       --target TARGET </span><br><span class="line">		--validation-source VALIDATION_SOURCE   --validation-target VALIDATION_TARGET</span><br><span class="line">		--output OUTPUT [...]</span><br></pre></td></tr></table></figure>
</blockquote>
<ul>
<li><p>训练一共需要5个参数：</p>
<ul>
<li><code>--source</code>,<code>--target</code>:  需要提供训练所需要的文件。支持<code>Gzipped</code>文件，前提是它们的文件名以 <code>.gz</code>结尾</li>
<li><code>--validation-source</code>, <code>--validation-target</code>:  需要提供连个验证集；<code>gzip</code>文件也同上</li>
<li><code>--output</code>: 给出将写入中间结果和最终结果的输出路径。如果需要中间结果，也可以提供中间结果的输出路径。日志会被写入到模型所在目录的log文件夹内，并且输出。</li>
</ul>
<blockquote>
<p>注：如果想知道更多的参数，可以考虑选择<code>--help</code>，来寻求帮助。</p>
</blockquote>
</li>
</ul>
<h5 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h5><p>所有的输入文件应该是<strong>UTF-8</strong>编码的，用标准的<strong>空格</strong>来标记。每一行包含一个单独的序列，源文件和目标文件应该包含相同的行数，词汇表将根据训练数据自动创建，并将报告初始化期间验证集的词汇表覆盖率。</p>
<h5 id="Checkpointing-and-early-stopping"><a href="#Checkpointing-and-early-stopping" class="headerlink" title="Checkpointing and early-stopping"></a>Checkpointing and early-stopping</h5><p>训练是通过<code>Checkpoints</code>这个概念来管理，而不是<code>epoch</code>。你可以更新/批次<code>--checkpoint-interval</code>来指定检查点的间隔。提前结束训练过程可以有效的避免过拟合，例如：一旦对给定的参数设置的检查点的数量没有改善，那么在给定的验证数据上计算的评估指标就会停止训练<code>--max-num-checkpoint-not-improved</code>。你可以指定一个最大数目的更新/批次通过使用<code>--max-updates</code>。</p>
<p><code>Perplexity</code>是作为提早停止训练的默认标准，但是您也可以使用<code>--optimized-metric</code> 参数选择优化准确性或BLEU 。如果要针对BLEU进行优化，则需要指定 <code>--monitor-bleu</code>。出于效率原因，<code>sockeye</code>在每个检查点之后都生成一个子过程，以对验证数据进行解码并计算BLEU。这可能会在结果报告中引入一些延迟，即，可能包括一些<code>checkpoints</code>没有包括BLEU的结果报告，一些结果数据和以前的<code>checkpoints</code>对应。这是预期的行为，sockeye内部会按照正确的顺序跟踪结果。</p>
<p>请注意，训练数据和保留的验证数据的评估指标将写入一个名为的制表符分隔文件中<code>metrics</code>。</p>
<p>对于每一个<code>checkpoints</code>，训练过程的内部状态都存储到磁盘上。如果训练过程被中断（硬盘问题），你可以再开始<code>sockeye</code>进程，则可以使用与初始训练相同的参数再次启动<code>sockeye</code>，训练过程将会从最后一个<code>checkpoint</code>恢复。请注意，这与使用<code>--params</code>参数不同。此参数仅用于使用模型参数的预先计算的值来初始化训练，而优化器和系统其他部分的参数是从头开始初始化的。</p>
<h5 id="使用可视化工具监视训练过程"><a href="#使用可视化工具监视训练过程" class="headerlink" title="使用可视化工具监视训练过程"></a>使用可视化工具监视训练过程</h5><p><code>Sockeye</code>可以使用<code>Tensorboard</code>兼容格式编写所有评估指标。这样你就可以在浏览器中监控训练进程。要启用此功能，请安装与mxnet兼容的接口mxboard:</p>
<blockquote>
<p>pip install mxboard</p>
</blockquote>
<p>为了可视化，你仍然需要官方的tensorboard版本(即 pip install tensorboard)。启动tensorboard并将其指向模型目录(或任何父目录):</p>
<blockquote>
<p>tensorboard –logdir model_dir</p>
</blockquote>
<h5 id="CPU-GPU训练"><a href="#CPU-GPU训练" class="headerlink" title="CPU/GPU训练"></a>CPU/GPU训练</h5><p>训练过程默认的是在你自己设备中的第一块GPU设备上执行。你可以选择，指定特定的GPU设备，利用<code>--device-ids</code>指令，你也可以多个GPU来训练。如果指令为<code>--device-ids -1</code>这种情况，<code>sockeye</code>将尝试在你的机器上找到一个空闲的GPU并阻塞，直到有一个可用。锁定机制基于文件，因此假定所有进程都运行在具有相同文件系统的同一台机器上。如果不是这种情况，有可能两个进程将使用相同的GPU和你用完GPU内存。如果你<strong>没有或者不想使用GPU</strong>，指定<code>--use-cpu</code>。在这种情况下，预期性能会下降。</p>
<h5 id="多个GPU训练"><a href="#多个GPU训练" class="headerlink" title="多个GPU训练"></a>多个GPU训练</h5><p>你可以利用多块GPU，通过指定GPU设备的id:<code>--device-ids 0 1 2 3</code>，或者指定需要GPU的块数：<code>--device-ids -n</code> （尝试获取<strong>n块</strong>GPU，利用上述描述的锁定机制）。这将使用数据并行性进行训练。MXNet将会将数据切分成若干干批次，然后将他们输入到不同的GPU设备中。在这里需要注意的是：你应该增加批次的数量：for k GPU s use <code>--bach-size k*&lt;original_batch_size&gt;</code>.还要注意，这可能会以句子/秒为单位线性增加您的吞吐量，但不一定会增加模型的收敛速度。</p>
<h5 id="Checkpoint-averaging"><a href="#Checkpoint-averaging" class="headerlink" title="Checkpoint averaging"></a>Checkpoint averaging</h5><p>提高模型性能的一种常见技术是对最后一个检查点的权重进行平均。可以这样做:</p>
<blockquote>
<p>python -m sockeye.average <model_dir> -o <model_dir>/model.best.avg.params</p>
</blockquote>
]]></content>
      <categories>
        <category>机器翻译</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>machine translate</tag>
      </tags>
  </entry>
  <entry>
    <title>亚马逊机器翻译框架-训练说明文档(0)</title>
    <url>/2019/11/18/%E4%BA%9A%E9%A9%AC%E9%80%8A%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E6%A1%86%E6%9E%B6-%E8%AE%AD%E7%BB%83%E8%AF%B4%E6%98%8E%E6%96%87%E6%A1%A3-3/</url>
    <content><![CDATA[<h3 id="Setup-amp-Installation"><a href="#Setup-amp-Installation" class="headerlink" title="Setup &amp; Installation"></a>Setup &amp; Installation</h3><h4 id="依存关系"><a href="#依存关系" class="headerlink" title="依存关系"></a>依存关系</h4><p><code>Sockeye</code>所需要的环境：</p>
<ul>
<li><strong>Python3</strong></li>
<li>MXNet</li>
<li>numpy</li>
</ul>
<h4 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h4><p>下面有几个有关<code>Sockeye</code>和他的依存关系安装选项。下面我们会罗列出几个备选方案，和一些相关的说明。</p>
<a id="more"></a>

<p>-&gt; <strong>via pip</strong></p>
<p>最简单的方式是使用pip:</p>
<blockquote>
<p>pip install sockeye</p>
</blockquote>
<p>如果你想在GPU上运行sockeye，你需要确保你的Apache MXNet孵化版本包含了GPU绑定。根据你的CUDA版本，你可以运行以下命令:</p>
<blockquote>
<p> wget <a href="https://raw.githubusercontent.com/awslabs/sockeye/master/requirements/requirements.gpu-cu${CUDA_VERSION}.txt" target="_blank" rel="noopener">https://raw.githubusercontent.com/awslabs/sockeye/master/requirements/requirements.gpu-cu${CUDA_VERSION}.txt</a></p>
<p>pip install sockeye –no-deps -r requirements.gpu-cu${CUDA_VERSION}.txt</p>
<p>rm requirements.gpu-cu${CUDA_VERSION}.txt</p>
</blockquote>
<p>其中，<strong>${CUDA_VERSION}</strong>可以被写成80(8.0)，90 (9.0), 92 (9.2), or 100 (10.0).分别对应的是CUDA的版本。</p>
<p>-&gt; <strong>via source…</strong></p>
<p>如果你只想使用sockeye而不扩展它，只需通过安装它即可：</p>
<blockquote>
<p>pip install -r requirements/requirements.txt</p>
<p>pip install .</p>
</blockquote>
<p>从github的仓库中克隆过来以后。</p>
<p>如果你想在GPU上运行sockeye，你需要确保你的Apache MXNet孵化版本包含了GPU绑定。根据你的CUDA版本，你可以运行以下命令:</p>
<blockquote>
<p>pip install -r requirements/requirements.gpu-cu${CUDA_VERSION}.txt</p>
<p>pip install .</p>
</blockquote>
<p>其中，<strong>${CUDA_VERSION}</strong>可以被写成80(8.0)，90 (9.0), 92 (9.2), or 100 (10.0).分别对应的是CUDA的版本。</p>
<p>开发人员最好将<code>$PYTHONPATH</code>指向git克隆源的根目录。</p>
<p>-&gt; 利用anaconda环境，其中，<code>anaconda</code>包含了conda、Python等180个多个科学包及依赖项。用户只需要运行以下行来安装sockeye(在一个没有GPU的实例上):</p>
<blockquote>
<p>conda create -n sockeye python=3.6 // 创建一个虚拟环境 sockeye</p>
<p>source activate sockeye     //激活环境</p>
<p>pip install sockeye –no-deps  //安装sockeye</p>
</blockquote>
<p>在使用GPU的实例上，下面的命令如下执行：</p>
<blockquote>
<p>conda create -n sockeye python=3.6</p>
<p>source activate sockeye</p>
<p>wget <a href="https://raw.githubusercontent.com/awslabs/sockeye/master/requirements/requirements.gpu-cu${CUDA_VERSION}.txt" target="_blank" rel="noopener">https://raw.githubusercontent.com/awslabs/sockeye/master/requirements/requirements.gpu-cu${CUDA_VERSION}.txt</a></p>
<p>pip install sockeye –no-deps -r requirements.gpu-cu${CUDA_VERSION}.txt</p>
<p>rm requirements.gpu-cu${CUDA_VERSION}.txt</p>
</blockquote>
<p>其中，<strong>${CUDA_VERSION}</strong>可以被写成80(8.0)，90 (9.0), 92 (9.2), or 100 (10.0).分别对应的是CUDA的版本。</p>
<h4 id="可选择的依赖关系"><a href="#可选择的依赖关系" class="headerlink" title="可选择的依赖关系"></a>可选择的依赖关系</h4><p>你可以安装Tensorboard来对训练过程可视化，您可以选择安装mxboard（<code>pip install mxboard</code>）。为了可视化过程，运行Tensorboard工具（<code>pip install tensorboard tensorflow</code>）日志目录指向训练输出文件夹：<code>tensorboard --logdir &lt;model&gt;</code>。</p>
<p>如果要创建对齐图，需要安装matplotlib（pip install matplotlib）。</p>
<h4 id="Running-sockeye"><a href="#Running-sockeye" class="headerlink" title="Running sockeye"></a>Running sockeye</h4><p>安装之后，可以使用诸如sockeye-train、sockeye-translate、sockeye-average和sockeye-embeddings之类的命令行工具。下面举例：</p>
<blockquote>
<p>sockeye-train <args></p>
</blockquote>
<p>同样，如果sockeye目录在$PYTHONPATH上，则可以直接运行模块:</p>
<blockquote>
<p>python -m sockeye.train <args></p>
</blockquote>
]]></content>
      <categories>
        <category>机器翻译</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>machine translate</tag>
      </tags>
  </entry>
  <entry>
    <title>Conda 安装命令大全</title>
    <url>/2019/11/18/Conda-%E5%AE%89%E8%A3%85%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8/</url>
    <content><![CDATA[<h2 id="Linux命令：经验总结"><a href="#Linux命令：经验总结" class="headerlink" title="Linux命令：经验总结"></a>Linux命令：经验总结</h2><h3 id="版本查看"><a href="#版本查看" class="headerlink" title="版本查看"></a>版本查看</h3><a id="more"></a>

<ol>
<li><p>cuda版本 查看</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat /usr/local/cuda/version.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>cudnn版本查看</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2</span><br></pre></td></tr></table></figure>



</li>
</ol>
<p>tensorflow的版本需要和cuda版本一致，才可以使用。</p>
<h3 id="conda创建虚拟环境"><a href="#conda创建虚拟环境" class="headerlink" title="conda创建虚拟环境"></a>conda创建虚拟环境</h3><ol>
<li><p>创建一个名为jfchen的环境，指定python版本是3.6</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conda create --name jfchen python=3.6</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看创建的所有环境</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conda list env  <span class="comment"># 指的是那些包</span></span><br><span class="line">conda info --envs <span class="comment"># 创建环境的名称</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>激活与关闭虚拟环境</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">source activate jfchen <span class="comment"># 激活环境</span></span><br><span class="line">source deactivate jfchen <span class="comment"># 关闭虚拟环境</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>删除环境</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conda remove --name jfchen --all</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h4 id="安装tensorflow"><a href="#安装tensorflow" class="headerlink" title="安装tensorflow"></a>安装tensorflow</h4><ol>
<li><p>使用pip安装</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># CPU版本</span></span><br><span class="line">pip install tensorflow==版本号</span><br><span class="line"></span><br><span class="line"><span class="comment"># GPU版本</span></span><br><span class="line">pip install tensorflow-gpu==版本号</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h4 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h4><ol>
<li><p>用Vim打开并编辑 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim ~/.bashrc</span><br></pre></td></tr></table></figure>
</li>
<li><p>重启环境</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看已安装的环境变量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo $PATH</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h4 id="退出xshell而进程不中断进程-screen命令"><a href="#退出xshell而进程不中断进程-screen命令" class="headerlink" title="退出xshell而进程不中断进程-screen命令"></a>退出xshell而进程不中断进程-screen命令</h4><ol>
<li><p>常见screen参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建一个名叫jfchen的session</span></span><br><span class="line">screen -S jfchen </span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出当前所有的session</span></span><br><span class="line">screen -ls</span><br><span class="line"></span><br><span class="line"><span class="comment"># 回到jfchen会话</span></span><br><span class="line">screen -r jfchen</span><br><span class="line"></span><br><span class="line"><span class="comment"># 远程detach某个session</span></span><br><span class="line">screen -d jfchen</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结束当前session并回到jfchen这个session</span></span><br><span class="line">screen -d -r jfchen</span><br></pre></td></tr></table></figure>







</li>
</ol>
]]></content>
      <categories>
        <category>指令</category>
      </categories>
      <tags>
        <tag>conda</tag>
        <tag>随笔</tag>
        <tag>linux</tag>
      </tags>
  </entry>
</search>
